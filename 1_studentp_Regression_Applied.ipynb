{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Dataset: Student Performance**"
      ],
      "metadata": {
        "id": "D1uY1IdNRJPA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Objective:**\n",
        "\n",
        "Apply Multiple Linear Regression Model on Student Performance dataset and train the model on the dataset to finally predict results on testing data.\n",
        "\n",
        "\n",
        "**Task**\n",
        "\n",
        "Our task is to:\n",
        "\n",
        "\n",
        "*   Preprocess the data, which includes feature scaling, outlier detection and treatment, checking normality of residuals, and  visualizing the data (use libraries i.e., matplotlib and seaborn).\n",
        "*   Model the data using a multiple linear regression model.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "jz2PsyemSzrk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Table of Contents**\n",
        "\n",
        "\n",
        "\n",
        "1. **Data Preprocessing**\n",
        "\n",
        " 1.1 Importing Libraries\n",
        " - Cell 1: Importing necessary libraries\n",
        " - Cell 2: Importing warnings\n",
        " - Cell 3: File upload\n",
        " 1.2 Understanding the Dataset\n",
        " - Cell 4: Displaying the first few rows of the dataset\n",
        " - Cell 5: Checking dataset shape\n",
        " - Cell 6: Examining datatypes in each column\n",
        " - Cell 7: Basic data information\n",
        " - Cell 8: Summary statistics\n",
        " 1.3 Handling Duplicate and Missing Values\n",
        " - Cell 9: Checking for duplicate rows\n",
        " - Cell 10: Encoding categorical feature 'Extracurricular Activities'\n",
        " - Cell 11: Counting rows\n",
        " - Cell 12: Checking for null values\n",
        " - Cell 13: Counting nulls per column\n",
        " - Cell 14: Dropping nulls\n",
        " - Cell 15: Heatmap to visualize any missing data\n",
        " 1.4 Target Variable and Feature Distribution\n",
        " - Cell 16: Distribution plot for 'Performance Index'\n",
        " 1.5 Correlation Analysis and Variance Inflation Factor (VIF)\n",
        " - Cell 17: Correlation matrix plot\n",
        " - Cell 18: Calculating VIF for each numerical feature\n",
        "\n",
        "2. **Exploratory Data Analysis (EDA) with Visualizations**\n",
        "\n",
        " 2.1 Distribution and Scatter Plots\n",
        " - Cell 19: Scatter plot of 'Hours Studied' vs. 'Performance Index'\n",
        " - Cell 19: Scatter plot of 'Previous Scores' vs. 'Performance Index'\n",
        " 2.2 Outlier Detection\n",
        " - Cell 20: Boxplot for outliers in 'Performance Index'\n",
        " 2.3 Count Plot\n",
        " - Cell 21: Count plot for 'Extracurricular Activities'\n",
        "3. **Linear Regression Model**\n",
        "\n",
        " 3.1 Model Setup and Feature Selection\n",
        " - Cell 22: Statistical model setup and summary\n",
        " - Cell 23: Dropping dependent variable from independent variables\n",
        " 3.2 Data Preparation for Regression\n",
        " - Cell 24-25: Shaping X (features) and y (target)\n",
        " - Cell 26: Splitting data into training and testing sets\n",
        " 3.3 Model Training and Prediction\n",
        " - Cell 27-28: Training X and y\n",
        " - Cell 29-30: Testing X and y\n",
        " - Cell 31: Calling and fitting linear regression model\n",
        " - Cell 32: Testing the model\n",
        " 3.4 Model Evaluation and Residual Analysis\n",
        " - Cell 33: Scatter plot of actual vs. predicted data points\n",
        " - Cell 34: Comparing actual and predicted values\n",
        " - Cell 35: Calculating residuals\n",
        " - Cell 36: Residual plot by order of observations\n",
        " - Cell 37: Residual plot vs. fitted values\n",
        " - Cell 38: Histogram and Q-Q plots of residuals for normality check\n",
        " 3.5 Model Performance Metrics\n",
        " - Cell 39: Calculating Mean Squared Error (MSE) and Root Mean Squared Error (RMSE)\n",
        " - Cell 40: Model evaluation with R-squared and RMSE\n",
        "\n"
      ],
      "metadata": {
        "id": "3sh9NWwcSz5l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **About the Dataset:**\n",
        "\n",
        "The Student Performance Dataset explores factors affecting student achievement, covering 10,000 records with various predictors and a performance index:\n",
        "\n",
        "- Hours Studied: Total hours each student studied.\n",
        "- Previous Scores: Past test scores of students.\n",
        "- Extracurricular Activities: Indicates if the student is involved in extracurriculars (Yes/No).\n",
        "- Sleep Hours: Average daily sleep hours.\n",
        "- Sample Question Papers Practiced: Number of sample papers practiced by each student.\n",
        "- Performance Index: Overall academic performance, ranging from 10 to 100, with higher scores indicating better results."
      ],
      "metadata": {
        "id": "ouw4ZF0yTnhx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Data Preprocessing**"
      ],
      "metadata": {
        "id": "DEy2dR-iXbOc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 1.  Import all the necessary libraries\n",
        "\n",
        "from google.colab import files\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "\n",
        "from sklearn.feature_selection import SelectKBest, f_regression\n",
        "from scipy import stats"
      ],
      "metadata": {
        "id": "RZFr8-_pXl0d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "8Q9XAIhInvPX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Upload the file\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Step 2: Load the CSV file into a DataFrame\n",
        "file_name = next(iter(uploaded))  # Get the uploaded file's name\n",
        "df = pd.read_csv(file_name)"
      ],
      "metadata": {
        "id": "VtB1RA-nX_ra"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: Display the first few rows of the DataFrame\n",
        "df.head()"
      ],
      "metadata": {
        "id": "SnjPFHj6YRVh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape\n"
      ],
      "metadata": {
        "id": "_lzkPehAZY7t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "df.dtypes"
      ],
      "metadata": {
        "id": "YGX7QYlXZos3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "5_8QxSQRbSoI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nDescriptive Statistics:\")\n",
        "df.describe()"
      ],
      "metadata": {
        "id": "hrUAv4xms_g4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "duplicate_rows_in_data =df[df.duplicated()]\n",
        "print(\"No. of Duplicate rows\", duplicate_rows_in_data.shape)\n",
        "duplicate_rows_in_data"
      ],
      "metadata": {
        "id": "f-ApYF-Tcfy7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert categorical column 'Extracurricular Activities' into numeric (1 for Yes, 0 for No)\n",
        "df['Extracurricular Activities'] = df['Extracurricular Activities'].apply(lambda x: 1 if x == 'Yes' else 0)\n",
        "\n",
        "df.head()"
      ],
      "metadata": {
        "id": "jelUA_WKhhXK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Point of attention 01: Dummy variable trap**\n",
        "\n",
        "\n",
        "* Our categorical column has just two values (1 and 0), it's already in a form that a model can handle without any issues.\n",
        "* Hence, we don't need to apply drop_first=True because there are no multiple dummy variables that could cause multicollinearity.\n",
        "\n",
        "**Point of attention 02: Dropping duplicate rows**\n",
        "\n"
      ],
      "metadata": {
        "id": "y_3EwNdchZ1B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.count()"
      ],
      "metadata": {
        "id": "dkYzIc8-bRen"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.isnull()"
      ],
      "metadata": {
        "id": "8DjB7fuujcbi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "JyOBjE1ujrXR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# we should drop missing values if any, it would drop all row if found any missing value\n",
        "df=df.dropna()\n",
        "\n",
        "df.count()"
      ],
      "metadata": {
        "id": "gOyr7Nfrj1FE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.heatmap(df.isnull(), yticklabels=False, cbar=False, cmap='tab20c_r')\n",
        "plt.title('Missing Data: Training Set')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "B-iuTLTrmE91"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "It means there are no missing values in the dataset"
      ],
      "metadata": {
        "id": "-uPIttWkmLpp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the distribution of the target variable 'Performance Index'\n",
        "plt.figure(figsize=(6, 4))\n",
        "sns.histplot(df['Performance Index'], kde=True, color='blue')\n",
        "plt.title('Distribution of Performance Index')\n",
        "plt.xlabel('Performance Index')\n",
        "plt.ylabel('Frequency')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "dSBKEADWr7v9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(5, 3))\n",
        "sns.heatmap(df.corr(), annot=True, cmap='coolwarm', linewidths=0.5)\n",
        "plt.title('Correlation Matrix')\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "drUIJM-slG6B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "from statsmodels.tools.tools import add_constant\n",
        "\n",
        "# Assuming 'df' is your dataframe with the independent variables\n",
        "\n",
        "# Select only numerical features for VIF calculation\n",
        "numerical_df = df.select_dtypes(include=['number'])\n",
        "\n",
        "# Add a constant to the model\n",
        "X = add_constant(numerical_df)\n",
        "\n",
        "# Create a dataframe to store VIF values\n",
        "vif = pd.DataFrame()\n",
        "vif[\"Feature\"] = X.columns\n",
        "# Calculate VIF for each numerical feature\n",
        "vif[\"VIF\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
        "\n",
        "print(vif)\n"
      ],
      "metadata": {
        "id": "M2-RVo7QejdN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Scatter plot between 'Hours Studied' and 'Performance Index'\n",
        "plt.figure(figsize=(6, 4))\n",
        "sns.scatterplot(x='Hours Studied', y='Performance Index', data=df, color='green')\n",
        "plt.title('Hours Studied vs. Performance Index')\n",
        "plt.xlabel('Hours Studied')\n",
        "plt.ylabel('Performance Index')\n",
        "plt.show()\n",
        "\n",
        "# Scatter plot between 'Previous Scores' and 'Performance Index'\n",
        "plt.figure(figsize=(6, 4))\n",
        "sns.scatterplot(x='Previous Scores', y='Performance Index', data=df, color='purple')\n",
        "plt.title('Previous Scores vs. Performance Index')\n",
        "plt.xlabel('Previous Scores')\n",
        "plt.ylabel('Performance Index')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Mgo68srFmdgC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Boxplot for detecting outliers in 'Performance Index'\n",
        "plt.figure(figsize=(6, 4))\n",
        "sns.boxplot(y='Performance Index', data=df, color='orange')\n",
        "plt.title('Boxplot of Performance Index')\n",
        "plt.ylabel('Performance Index')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "dxi5IbkDnX9N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Count plot for 'Extracurricular Activities' to check the distribution of students involved in activities\n",
        "plt.figure(figsize=(6, 4))\n",
        "sns.countplot(x='Extracurricular Activities', data=df, palette='Set2')\n",
        "plt.title('Distribution of Extracurricular Activities')\n",
        "plt.xlabel('Extracurricular Activities (1 = Yes, 0 = No)')\n",
        "plt.ylabel('Count')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "hxCU6WumnkHZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(6, 4))\n",
        "sns.scatterplot(x='Extracurricular Activities', y='Performance Index', data=df, color='purple')\n",
        "plt.title('Extracurricular Activities vs. Performance Index')\n",
        "plt.xlabel('Extracurricular Activities')\n",
        "plt.ylabel('Performance Index')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "slepPql0-gCh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import statsmodels.api as sm\n",
        "\n",
        "# Define the independent variables (your features)\n",
        "X = df[['Hours Studied', 'Previous Scores', 'Extracurricular Activities', 'Sleep Hours', 'Sample Question Papers Practiced']]\n",
        "\n",
        "# Dependent variable (target)\n",
        "y = df['Performance Index']\n",
        "\n",
        "# Add constant (for intercept)\n",
        "X = sm.add_constant(X)\n",
        "\n",
        "# Fit the multiple linear regression model\n",
        "model = sm.OLS(y, X).fit()\n",
        "\n",
        "# Print model summary\n",
        "print(model.summary())"
      ],
      "metadata": {
        "id": "UtNZkV6mjK-a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Drop 'Performance Index' from df to create x\n",
        "x = df.drop('Performance Index', axis=1)\n",
        "\n",
        "# Assign 'Performance Index' to y\n",
        "y = df['Performance Index']"
      ],
      "metadata": {
        "id": "B7mGc3Z2kBkx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x.shape"
      ],
      "metadata": {
        "id": "-J3Bpz90kQH9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y.shape"
      ],
      "metadata": {
        "id": "3WEhJWLykUpY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into training and testing sets\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=101)"
      ],
      "metadata": {
        "id": "2WYkr4EzkYdF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train.shape\n",
        "x_train"
      ],
      "metadata": {
        "id": "WhGgUwxNkfoa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train"
      ],
      "metadata": {
        "id": "jIE6oD8akkp2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_test"
      ],
      "metadata": {
        "id": "tilEgJnskxUq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_test"
      ],
      "metadata": {
        "id": "9NmKtGNXk3Ua"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "linear_reg =LinearRegression()\n",
        "\n",
        "linear_reg.fit(x_train,y_train)"
      ],
      "metadata": {
        "id": "Tfc7Z01Ek9uu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Model Testing**"
      ],
      "metadata": {
        "id": "dgEJK574lKyp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred=linear_reg.predict(x_test)\n",
        "print(y_pred.shape)\n",
        "print(y_pred)"
      ],
      "metadata": {
        "id": "Zhl09TqslGP5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.scatterplot(x=y_test,y=y_pred,color='green',label='Actual Data Points')\n",
        "sns.lineplot(x=[min(y_test),max(y_test)],y=[min(y_pred),max(y_pred)] , color='red',label='Predicted/IDEAL Line')\n",
        "plt.legend()\n",
        "plt.show"
      ],
      "metadata": {
        "id": "0jqx6BtXlUmf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#combine actual and predicted values\n",
        "\n",
        "results=np.column_stack([y_test,y_pred])\n",
        "print('Actual Values  |    Predicted Values')\n",
        "print('____________________________________')\n",
        "\n",
        "for actual,predicted in results:\n",
        "  print(f'{actual:15.2f}  |  {predicted:15.2f}')"
      ],
      "metadata": {
        "id": "56jIkOVWlh_e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "residual=actual-y_pred\n",
        "print(residual)"
      ],
      "metadata": {
        "id": "fGpKbDcLluFV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "residuals=y_test-y_pred\n",
        "print(residuals)"
      ],
      "metadata": {
        "id": "Y0G3fCOClxyV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot residuals over the order of observations to check independence\n",
        "plt.figure(figsize=(6, 4))\n",
        "plt.plot(range(len(residuals)), residuals, marker='o', linestyle='', color='blue')\n",
        "plt.axhline(y=0, color='red', linestyle='--')\n",
        "plt.title('Independence Check: Residuals over Observations')\n",
        "plt.xlabel('Observation Order')\n",
        "plt.ylabel('Residuals')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "qv-ZQf0Al4r4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes, it is independent\n",
        "\n",
        "\n",
        "Independent --> yes"
      ],
      "metadata": {
        "id": "Nb_AW6clmQoQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot residuals vs. fitted values to check homoscedasticity\n",
        "plt.figure(figsize=(6, 4))\n",
        "plt.scatter(y_pred, residuals, color='blue')\n",
        "plt.axhline(y=0, color='red', linestyle='--')\n",
        "plt.title('Homoscedasticity Check: Residuals vs. Predicted Values')\n",
        "plt.xlabel('Predicted Values')\n",
        "plt.ylabel('Residuals')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "unk4BkFkmNBl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "It is Homoscedastic"
      ],
      "metadata": {
        "id": "TDi-jYzsmdiI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Histogram of residuals to check normality\n",
        "plt.figure(figsize=(6, 4))\n",
        "sns.histplot(residuals, kde=True, color='darkgreen')\n",
        "plt.title('Normality Check: Histogram of Residuals')\n",
        "plt.xlabel('Residuals')\n",
        "plt.ylabel('Frequency')\n",
        "plt.show()\n",
        "\n",
        "# Q-Q plot to further check for normality\n",
        "import scipy.stats as stats\n",
        "fig, ax = plt.subplots(figsize=(6, 4))\n",
        "stats.probplot(residuals, dist=\"norm\", plot=ax)\n",
        "plt.title('Q-Q Plot of Residuals')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "WZUU5nj2mcxe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "It is almost a normal chart both in prediction and actual dataset."
      ],
      "metadata": {
        "id": "VCKV9trrmubK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Model Evaluation**"
      ],
      "metadata": {
        "id": "mZ79sBninLU5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "print(\"Linear Regression Model\")\n",
        "mse=mean_squared_error(y_test, y_pred)\n",
        "rmse=np.sqrt(mse)\n",
        "print(\"MSE: \", mse)\n",
        "print(\"RMSE: \", rmse)"
      ],
      "metadata": {
        "id": "OU0rFHaLnJmm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluating the model using R-squared and RMSE\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(f\"R-squared: {r2}\")"
      ],
      "metadata": {
        "id": "PHiUoFKfnTiA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model is 98.8% expressible by the independent varabiales we have taken.\n",
        "\n",
        "Model is quite Expressible."
      ],
      "metadata": {
        "id": "F3EVB51IncHH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('Coefficients: ', model.coef_)"
      ],
      "metadata": {
        "id": "xRupWzanshJl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.rsquared)"
      ],
      "metadata": {
        "id": "kRaZ0uijsjZO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Questions**\n",
        "\n",
        "1. What role do the coefficients (slopes) play in Linear Regression? How would you interpret them in the context of our dataset?\n",
        " \tIn linear regression, coefficients (or slopes) quantify the relationship between each independent variable and the dependent variable. They indicate how much the dependent variable is expected to change for a one-unit increase in a given independent variable while keeping all other variables constant. For instance, if the coefficient for \"Hours Studied\" is 0.5, it suggests that for every additional hour spent studying, the \"Performance Index\" increases by an average of 0.5 points, assuming no changes in other factors.\n",
        "\n",
        "2. What are the independent (predictor) and dependent (target) variables in this dataset?\n",
        "\n",
        " \tIndependent (predictor) variables: These are the variables employed in order to estimate the target variable. From the dataset, independent variables are:\n",
        "a) Hours Studied\n",
        "b) Previous Scores\n",
        "c) Extracurricular Activities\n",
        "d) Sleep Hours\n",
        "Dependent (target) Variables: This is the variable you seek to predict.\n",
        "The dependent variables in dataset are:\n",
        "a)\tPerformance Index\n",
        "\n",
        "\n",
        "3. What happens when we increase the number of features (independent variables) in a Linear Regression model? How does it affect accuracy?\n",
        "\n",
        " \tMore features increase model complexity, enhancing performance on training data but increasing the chance of overfitting, which takes innoise rather than real patterns. Overfitting is where the model gives poor generalization and makes it perform less optimally on unseendata.\n",
        "\n",
        "Effect on Accuracy: Accuracy would get better first before the increaseof additional features might actually result in decreased accuracy inunseen data based on overfitting.\n",
        "\n",
        "\n",
        "4. What does the output summary of the model tell us about the statistical significance of each feature?\n",
        "\n",
        " \tThe output summary gives an insight into the statistical significance of the features in the model. It gives important measures like p-values, t-values, and the confidence intervals of the coefficients.\n",
        "\n",
        "Statistical Significance: Low p-values (usually lower than 0.05) are usedfor significant features; that is, there is great evidence that thesefeatures affect the dependent variable.\n",
        "\n",
        "\n",
        "5. If we observe that the model has high training accuracy but low testing accuracy, what does that indicate?\n",
        "\n",
        " \tThis behavior indicates overfitting, i.e., the model's strong performanceon the training set and poor ability to generalize for new data.\n",
        "\n",
        "Solution: The model has captured some patterns—and even noise—towards which the model no longer generalizes well. For the solution to this, simplifying the model would be recommended, e.g., by the elimination of certain features or application of regularization strategies.\n",
        "\n"
      ],
      "metadata": {
        "id": "a478n1LZnk-b"
      }
    }
  ]
}